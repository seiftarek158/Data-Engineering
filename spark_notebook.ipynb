{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d75c7291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark  \n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1da6f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark with proper configuration for Windows\n",
    "spark = SparkSession.builder \\\n",
    ".appName(\"SparkAppName\") \\\n",
    ".master(\"spark://spark-master:7077\") \\\n",
    ".getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(\"Spark Session initialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "044a2580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded CSV file: /app/data/FULL_STOCKS.csv\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"/app/data/FULL_STOCKS.csv\"\n",
    "df = spark.read.csv(csv_path, header=True, inferSchema=True)\n",
    "\n",
    "print(f\"\\nLoaded CSV file: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2f37f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 records:\n",
      "+--------------+----------+-----------+------------+----------------+--------+------------------+-----------------+------------------+---------------------+----------+----------+--------------------+------------+--------------+----------+----------+------------+-----------+-------------+\n",
      "|transaction_id| timestamp|customer_id|stock_ticker|transaction_type|quantity|average_trade_size|      stock_price|total_trade_amount|customer_account_type|is_weekend|is_holiday|stock_liquidity_tier|stock_sector|stock_industry|day_Friday|day_Monday|day_Thursday|day_Tuesday|day_Wednesday|\n",
      "+--------------+----------+-----------+------------+----------------+--------+------------------+-----------------+------------------+---------------------+----------+----------+--------------------+------------+--------------+----------+----------+------------+-----------+-------------+\n",
      "|             1|2023-01-02|       4747|           1|               0|      15|             139.4|4.967956350196401| 2155.992711157844|                    1|         0|         0|                 Low|           0|             5|         0|         1|           0|          0|            0|\n",
      "|             2|2023-01-02|       4747|           3|               0|      68|             139.4|3.731006681134751| 2837.033906613808|                    1|         0|         0|                 Low|           2|             0|         0|         1|           0|          0|            0|\n",
      "|             3|2023-01-02|        227|           5|               0|      49|             139.4|4.917153784174474| 6694.048200413102|                    1|         0|         0|                High|           1|             2|         0|         1|           0|          0|            0|\n",
      "|             4|2023-01-02|       4747|           5|               0|     503|            195.33|4.917153784174474|  68716.4539756692|                    1|         0|         0|                High|           1|             2|         0|         1|           0|          0|            0|\n",
      "|             5|2023-01-02|       3938|           5|               0|     203|             203.0|4.917153784174474|27732.485401711423|                    1|         0|         0|                High|           1|             2|         0|         1|           0|          0|            0|\n",
      "|             6|2023-01-02|       1513|           5|               0|     114|             139.4|4.917153784174474|15573.908058103952|                    1|         0|         0|                High|           1|             2|         0|         1|           0|          0|            0|\n",
      "|             7|2023-01-02|       4167|           5|               0|     119|             139.4|4.917153784174474|16256.974201003248|                    1|         0|         0|                High|           1|             2|         0|         1|           0|          0|            0|\n",
      "|             8|2023-01-02|       1513|           5|               0|      91|             139.4|4.917153784174474| 12431.80380076719|                    1|         0|         0|                High|           1|             2|         0|         1|           0|          0|            0|\n",
      "|             9|2023-01-02|       4955|           5|               0|     339|            254.21|4.917153784174474| 46311.88448857228|                    1|         0|         0|                High|           1|             2|         0|         1|           0|          0|            0|\n",
      "|            10|2023-01-02|       4747|           5|               1|     285|            217.75|4.917153784174474| 38934.77014525988|                    1|         0|         0|                High|           1|             2|         0|         1|           0|          0|            0|\n",
      "+--------------+----------+-----------+------------+----------------+--------+------------------+-----------------+------------------+---------------------+----------+----------+--------------------+------------+--------------+----------+----------+------------+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFirst 10 records:\")\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40ea32c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Total trading volume for each stock ticker:\n",
      "+------------+------------+\n",
      "|stock_ticker|total_volume|\n",
      "+------------+------------+\n",
      "|          12|      152604|\n",
      "|           1|        4405|\n",
      "|          13|        1512|\n",
      "|           6|       28486|\n",
      "|          16|       35435|\n",
      "|           3|        2857|\n",
      "|           5|      611667|\n",
      "|          19|       49724|\n",
      "|          15|        3210|\n",
      "|           9|      125862|\n",
      "|          17|      153811|\n",
      "|           4|        6997|\n",
      "|           8|      314915|\n",
      "|           7|      104680|\n",
      "|          10|       32119|\n",
      "|          11|      428057|\n",
      "|          14|        3302|\n",
      "|           2|        8570|\n",
      "|           0|        3557|\n",
      "|          18|       34229|\n",
      "+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. Total trading volume for each stock ticker:\")\n",
    "q1_result = df.groupBy(\"stock_ticker\") \\\n",
    "    .agg(fn.sum(\"quantity\").alias(\"total_volume\")) \n",
    "q1_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57b21b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Average stock price by sector:\n",
      "+------------+------------------+\n",
      "|stock_sector|   avg_stock_price|\n",
      "+------------+------------------+\n",
      "|           1| 101.5326450467328|\n",
      "|           3|152.00790316478066|\n",
      "|           4|153.67922533016065|\n",
      "|           2| 79.92351314619141|\n",
      "|           0|213.62484690770114|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 2: What is the average stock price by sector?\n",
    "print(\"\\n2. Average stock price by sector:\")\n",
    "q2_result = df.groupBy(\"stock_sector\") \\\n",
    "    .agg(fn.avg(fn.exp(fn.col(\"stock_price\"))).alias(\"avg_stock_price\")) \n",
    "q2_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe71d330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Buy vs Sell transactions on weekends:\n",
      "+----------------+-----------------+\n",
      "|transaction_type|transaction_count|\n",
      "+----------------+-----------------+\n",
      "+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 3: How many buy vs sell transactions occurred on weekends?\n",
    "print(\"\\n3. Buy vs Sell transactions on weekends:\")\n",
    "q3_result = df.filter(fn.col(\"is_weekend\") == 1) \\\n",
    "    .groupBy(\"transaction_type\") \\\n",
    "    .agg(fn.count(\"transaction_id\").alias(\"transaction_count\")) \n",
    "q3_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4642d2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Customers with more than 10 transactions:\n",
      "Total customers with >10 transactions: 74\n",
      "+-----------+-----------------+\n",
      "|customer_id|transaction_count|\n",
      "+-----------+-----------------+\n",
      "|       4519|              284|\n",
      "|       1903|               11|\n",
      "|       1157|              227|\n",
      "|       4697|               17|\n",
      "|       3087|               12|\n",
      "|        193|              419|\n",
      "|       1243|               13|\n",
      "|       1816|               86|\n",
      "|       4700|               63|\n",
      "|       2871|               29|\n",
      "|       2750|               13|\n",
      "|        192|               41|\n",
      "|       4354|               15|\n",
      "|        336|               20|\n",
      "|       2920|               19|\n",
      "|        319|               17|\n",
      "|       3498|               39|\n",
      "|       4987|               14|\n",
      "|        363|               15|\n",
      "|        182|              162|\n",
      "+-----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 4: Which customers have made more than 10 transactions?\n",
    "print(\"\\n4. Customers with more than 10 transactions:\")\n",
    "q4_result = df.groupBy(\"customer_id\") \\\n",
    "    .agg(fn.count(\"transaction_id\").alias(\"transaction_count\")) \\\n",
    "    .filter(fn.col(\"transaction_count\") > 10) \n",
    "print(f\"Total customers with >10 transactions: {q4_result.count()}\")\n",
    "q4_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c69c20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Total trade amount per day of the week (highest to lowest):\n",
      "+---------+--------------------+\n",
      "|      day|  total_trade_amount|\n",
      "+---------+--------------------+\n",
      "| Thursday|6.0742740599982046E7|\n",
      "|Wednesday| 5.930424152755955E7|\n",
      "|   Monday|5.8715772269690834E7|\n",
      "|   Friday| 5.809313014764415E7|\n",
      "|  Tuesday|5.2834481894753695E7|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 5: What is the total trade amount per day of the week, ordered from highest to lowest?\n",
    "print(\"\\n5. Total trade amount per day of the week (highest to lowest):\")\n",
    "\n",
    "# one-hot encoded day columns\n",
    "day_cols = [\"day_Monday\", \"day_Tuesday\", \"day_Wednesday\", \"day_Thursday\", \"day_Friday\"]\n",
    "\n",
    "# compute total trade amount for each day by filtering on the one-hot flag\n",
    "sums = []\n",
    "for col in day_cols:\n",
    "    total = df.filter(fn.col(col) == 1) \\\n",
    "              .agg(fn.sum(\"total_trade_amount\").alias(\"total\")) \\\n",
    "              .collect()[0][\"total\"]\n",
    "    total = float(total) if total is not None else 0.0\n",
    "    sums.append((col.replace(\"day_\", \"\"), total))\n",
    "\n",
    "# create a Spark DataFrame and order by total_trade_amount desc\n",
    "q5_result = spark.createDataFrame(sums, [\"day\", \"total_trade_amount\"]) \\\n",
    "                 .orderBy(fn.desc(\"total_trade_amount\"))\n",
    "\n",
    "q5_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdadb1b",
   "metadata": {},
   "source": [
    "## Spark SQL Analysis Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0684e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register DataFrame as temporary SQL table\n",
    "df.createOrReplaceTempView(\"trades\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99669aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL 1. Top 5 most traded stock tickers by total quantity:\n",
      "+------------+--------------+\n",
      "|stock_ticker|total_quantity|\n",
      "+------------+--------------+\n",
      "|           5|        611667|\n",
      "|          11|        428057|\n",
      "|           8|        314915|\n",
      "|          17|        153811|\n",
      "|          12|        152604|\n",
      "+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Question 1: What are the top 5 most traded stock tickers by total quantity?\n",
    "print(\"SQL 1. Top 5 most traded stock tickers by total quantity:\")\n",
    "sql1_result = spark.sql(\"\"\"\n",
    "    SELECT stock_ticker, \n",
    "           SUM(quantity) as total_quantity\n",
    "    FROM trades\n",
    "    GROUP BY stock_ticker\n",
    "    ORDER BY total_quantity DESC\n",
    "    LIMIT 5\n",
    "\"\"\")\n",
    "sql1_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f885936a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SQL 2. Average trade amount by customer account type:\n",
      "+-------------+------------------+\n",
      "| account_type|  avg_trade_amount|\n",
      "+-------------+------------------+\n",
      "|       Retail|29253.766554710597|\n",
      "|Institutional|26043.733739066804|\n",
      "+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Question 2: What is the average trade amount by customer account type?\n",
    "print(\"\\nSQL 2. Average trade amount by customer account type:\")\n",
    "sql2_result = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        CASE customer_account_type\n",
    "            WHEN 0 THEN 'Institutional'\n",
    "            ELSE 'Retail'\n",
    "        END as account_type,\n",
    "        AVG(total_trade_amount) as avg_trade_amount\n",
    "    FROM trades\n",
    "    GROUP BY customer_account_type\n",
    "\"\"\")\n",
    "sql2_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ad2ffe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL 3. Transactions during holidays vs non-holidays:\n",
      "+-----------+-----------------+\n",
      "|period_type|transaction_count|\n",
      "+-----------+-----------------+\n",
      "|    Holiday|              180|\n",
      "|Non-Holiday|             9820|\n",
      "+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Question 3: How many transactions occurred during holidays vs non-holidays?\n",
    "print(\"SQL 3. Transactions during holidays vs non-holidays:\")\n",
    "sql3_result = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        CASE is_holiday\n",
    "            WHEN 1 THEN 'Holiday'\n",
    "            ELSE 'Non-Holiday'\n",
    "        END as period_type,\n",
    "        COUNT(transaction_id) as transaction_count\n",
    "    FROM trades\n",
    "    GROUP BY is_holiday\n",
    "\"\"\")\n",
    "sql3_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c7cf4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SQL 4. Stock sectors with highest total trading volume on weekends:\n",
      "+------------+------------+\n",
      "|stock_sector|total_volume|\n",
      "+------------+------------+\n",
      "+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Question 4: Which stock sectors had the highest total trading volume on weekends?\n",
    "print(\"\\nSQL 4. Stock sectors with highest total trading volume on weekends:\")\n",
    "sql4_result = spark.sql(\"\"\"\n",
    "    SELECT stock_sector,\n",
    "           SUM(quantity) as total_volume\n",
    "    FROM trades\n",
    "    WHERE is_weekend = 1\n",
    "    GROUP BY stock_sector\n",
    "    ORDER BY total_volume DESC\n",
    "\"\"\")\n",
    "sql4_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e35d1d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SQL 5. Total buy vs sell amount for each stock liquidity tier:\n",
      "+--------------------+----------------+--------------------+\n",
      "|stock_liquidity_tier|transaction_type|        total_amount|\n",
      "+--------------------+----------------+--------------------+\n",
      "|                High|            SELL| 6.118042233749355E7|\n",
      "|                High|             BUY|1.6443413419306594E8|\n",
      "|                 Low|             BUY|   2599141.018825055|\n",
      "|                 Mid|            SELL|1.5581928747374471E7|\n",
      "|                 Mid|             BUY| 4.549252643164398E7|\n",
      "|                 Low|            SELL|  402213.71122708963|\n",
      "+--------------------+----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Question 5: What is the total buy vs sell amount for each stock liquidity tier?\n",
    "print(\"\\nSQL 5. Total buy vs sell amount for each stock liquidity tier:\")\n",
    "sql5_result = spark.sql(\"\"\"\n",
    "    SELECT stock_liquidity_tier,\n",
    "           CASE transaction_type\n",
    "               WHEN 0 THEN 'BUY'\n",
    "                ELSE  'SELL'\n",
    "           END as transaction_type,\n",
    "           SUM(total_trade_amount) as total_amount\n",
    "    FROM trades\n",
    "    GROUP BY stock_liquidity_tier, transaction_type\n",
    "\"\"\")\n",
    "sql5_result.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
